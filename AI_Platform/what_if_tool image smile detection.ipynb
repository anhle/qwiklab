{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"what_if_tool image smile detection.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO3fLpLj7ihFmsRStUkWjGM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wRUuQCxO6x1b","colab_type":"text"},"source":["#What-If Tool Image Smile Detection\n","In this demo we demonstrate the use of what-if-tool for image recognition models. Our task is to predict if a person is smiling or not. We provide a CNN that is trained on a subset of CelebA dataset and visualize the results on a separate test subset.\n","\n","git clone https://github.com/GoogleCloudPlatform/training-data-analyst\n","\n","Navigate to training-data-analyst\\quests\\dei and open WIT_Smile_Detector.ipynb\n","\n","This notebook shows use of the [What-If Tool](https://pair-code.github.io/what-if-tool) inside of a colab or jupyter notebook.\n","\n","In this lab, you will perform the following tasks:\n","\n","1. Download the pre-trained Keras model.\n","\n","2. Define helper functions for dataset conversion from csv to tf.\n","\n","3. Load the csv file into pandas dataframe and process it for WIT.\n","\n","4. Load the Keras models.\n","\n","5. Define the custom predict function for WIT."]},{"cell_type":"code","metadata":{"id":"w1Y4pPUa6qkj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599337339100,"user_tz":300,"elapsed":1462,"user":{"displayName":"Anh Le","photoUrl":"","userId":"14028814064442584144"}}},"source":["# Ensure the right version of Tensorflow is installed.\n","!pip freeze | grep tensorflow==2.1"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wCqJhYv-eX3","colab_type":"code","colab":{}},"source":["#@title Install the What-If Tool widget if running in Colab {display-mode: \"form\"}\n","\n","# If running in Colab then pip install, otherwise no need.\n","try:\n","  import google.colab\n","  !pip install --upgrade witwidget\n","except Exception:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mZa92vQa77zC","colab_type":"text"},"source":["# Download the pretrained keras model files and subset of celeba images"]},{"cell_type":"code","metadata":{"id":"8klOQfpJ8Fwc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"status":"ok","timestamp":1599337427186,"user_tz":300,"elapsed":1532,"user":{"displayName":"Anh Le","photoUrl":"","userId":"14028814064442584144"}},"outputId":"cd77e193-50c1-4878-99df-2c0cde95a15f"},"source":["!curl -L https://storage.googleapis.com/what-if-tool-resources/smile-demo/smile-colab-model.hdf5 -o ./smile-model.hdf5\n","!curl -L https://storage.googleapis.com/what-if-tool-resources/smile-demo/test_subset.zip -o ./test_subset.zip\n","!unzip -qq -o test_subset.zip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 39.6M  100 39.6M    0     0  73.8M      0 --:--:-- --:--:-- --:--:-- 73.8M\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 3819k  100 3819k    0     0  30.8M      0 --:--:-- --:--:-- --:--:-- 30.8M\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y__nw7Q68LGV","colab_type":"text"},"source":["# Define helper functions for dataset conversion from csv to tf.Examples"]},{"cell_type":"code","metadata":{"id":"wgtugFGU8RJm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599337483000,"user_tz":300,"elapsed":2141,"user":{"displayName":"Anh Le","photoUrl":"","userId":"14028814064442584144"}}},"source":["import numpy as np\n","import tensorflow as tf\n","import os\n","from PIL import Image\n","from io import BytesIO\n","\n","# Converts a dataframe into a list of tf.Example protos.\n","# If images_path is specified, it assumes that the dataframe has a special \n","# column \"image_id\" and the path \"images_path/image_id\" points to an image file.\n","# Given this structure, this function loads and processes the images as png byte_lists\n","# into tf.Examples so that they can be shown in WIT. Note that 'image/encoded'\n","# is a reserved field in WIT for encoded image features.\n","def df_to_examples(df, columns=None, images_path=''):\n","  examples = []\n","  if columns == None:\n","    columns = df.columns.values.tolist()\n","  for index, row in df.iterrows():\n","    example = tf.train.Example()\n","    for col in columns:\n","      if df[col].dtype is np.dtype(np.int64):\n","        example.features.feature[col].int64_list.value.append(int(row[col]))\n","      elif df[col].dtype is np.dtype(np.float64):\n","        example.features.feature[col].float_list.value.append(row[col])\n","      elif row[col] == row[col]:\n","        example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n","    if images_path:\n","      fname = row['image_id']\n","      with open(os.path.join(images_path, fname), 'rb') as f:\n","        im = Image.open(f)\n","        buf = BytesIO()\n","        im.save(buf, format= 'PNG')\n","        im_bytes = buf.getvalue()\n","        example.features.feature['image/encoded'].bytes_list.value.append(im_bytes)\n","    examples.append(example)\n","  return examples\n","\n","# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n","# Used to force label columns to be numeric for binary classification using a TF estimator.\n","def make_label_column_numeric(df, label_column, test):\n","  df[label_column] = np.where(test(df[label_column]), 1, 0)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WKud6wsp8OzF","colab_type":"text"},"source":["# Load the csv file into pandas dataframe and process it for WIT¶"]},{"cell_type":"code","metadata":{"id":"iVRAu_QL8bQe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599337554463,"user_tz":300,"elapsed":6134,"user":{"displayName":"Anh Le","photoUrl":"","userId":"14028814064442584144"}}},"source":["import pandas as pd\n","\n","data = pd.read_csv('celeba/data_test_subset.csv')\n","examples = df_to_examples(data, images_path='celeba/img_test_subset_resized/')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gKZKAnie8evj","colab_type":"text"},"source":["# Load the keras models"]},{"cell_type":"code","metadata":{"id":"7KGNLCPC8ikv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599337602338,"user_tz":300,"elapsed":470,"user":{"displayName":"Anh Le","photoUrl":"","userId":"14028814064442584144"}}},"source":["from tensorflow.keras.models import load_model\n","\n","model1 = load_model('smile-model.hdf5')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qcjAJj-H8qnR","colab_type":"text"},"source":["# Define the custom predict function for WIT"]},{"cell_type":"code","metadata":{"id":"yXyH3rcr8vaM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599337604618,"user_tz":300,"elapsed":290,"user":{"displayName":"Anh Le","photoUrl":"","userId":"14028814064442584144"}}},"source":["# This function extracts 'image/encoded' field, which is a reserved key for the \n","# feature that contains encoded image byte list. We read this feature into \n","# BytesIO and decode it back to an image using PIL.\n","# The model expects an array of images that are floats in range 0.0 to 1.0 and \n","# outputs a numpy array of (n_samples, n_labels)\n","def custom_predict(examples_to_infer):\n","  def load_byte_img(im_bytes):\n","    buf = BytesIO(im_bytes)\n","    return np.array(Image.open(buf), dtype=np.float64) / 255.\n","\n","  ims = [load_byte_img(ex.features.feature['image/encoded'].bytes_list.value[0]) \n","         for ex in examples_to_infer]\n","  preds = model1.predict(np.array(ims))\n","  return preds"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M6Vw8knR81Pc","colab_type":"text"},"source":["Note that this particular model only uses images as input. Therefore, partial dependence plots are flat for all features. These features are provided for slicing and analysis purposes.\n","Invoke What-If Tool for the data and model {display-mode: \"form\"}¶"]},{"cell_type":"code","metadata":{"id":"DMgTRgUe85ie","colab_type":"code","colab":{}},"source":["import witwidget\n","from witwidget.notebook.visualization import WitWidget, WitConfigBuilder, display\n","\n","num_datapoints = 250 \n","tool_height_in_px = 700\n","\n","# Decode an image from tf.example bytestring\n","def decode_image(ex):\n","  im_bytes = ex.features.feature['image/encoded'].bytes_list.value[0]\n","  im = Image.open(BytesIO(im_bytes))\n","  return im\n","\n","# Define the custom distance function that compares the average color of images\n","def image_mean_distance(ex, exs, params):\n","  selected_im = decode_image(ex)\n","  mean_color = np.mean(selected_im, axis=(0,1))\n","  image_distances = [np.linalg.norm(mean_color - np.mean(decode_image(e), axis=(0,1))) for e in exs]\n","  return image_distances\n","\n","# Setup the tool with the test examples and the trained classifier\n","config_builder = WitConfigBuilder(examples[:num_datapoints]).set_custom_predict_fn(\n","    custom_predict).set_custom_distance_fn(image_mean_distance)\n","\n","wv = WitWidget(config_builder, height=tool_height_in_px)\n","display(wv)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T2Y4oJoj8_WR","colab_type":"text"},"source":["## Exploration ideas\n","\n","- In the \"Performance\" tab, set the ground truth feature to \"Smiling\". You can set a scatter axis or binning option to be inference correct and analyze how it varies across other features (i.e. you can make a scatter plot of Young vs inference correct).\n","- Choose an image and click on \"Show nearest counterfactual datapoint\", this will find another example that is closest to the selected image in terms of average color value, but has a different prediction (if selected image is predicted to be \"smiling\" the counterfactual one will have \"not smiling\" prediction).\n","- Define your own custom distance function and set it by calling set_custom_distance_fn on config_builder and explore the counterfactuals. You can even load another neural network to compute distances!\n","- You can slice by any one of the features and analyze the confusion matrix and accuracy for each group.\n","- In the \"Datapoint Editor\" tab, you can upload your own image or download and modify one of the images to see how it affects the inference score."]}]}